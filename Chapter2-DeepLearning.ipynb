{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0edd3526",
   "metadata": {},
   "source": [
    "# 深度学习\n",
    "是一类机器学习算法，使用多个堆叠层的处理单元来学习非结构化数据的高层表征。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56c2daee",
   "metadata": {},
   "source": [
    "## 数据"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea0c26d2",
   "metadata": {},
   "source": [
    "### 结构化数据与非结构化数据\n",
    "\n",
    "**结构化数据**：\n",
    "- 自然地排列成特征列\n",
    "- 如年龄、收入、网站访问次数\n",
    "- 每个特征本身包含信息片段\n",
    "- 适合传统机器学习模型（逻辑回归、随机森林等）\n",
    "\n",
    "**非结构化数据**：\n",
    "- 不按特征列排列\n",
    "- 如图像、音频、文本、视频\n",
    "- 单个元素（像素、字符）几乎无信息量\n",
    "- 需要深度学习提取高级特征"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c9cb98c",
   "metadata": {},
   "source": [
    "### 为什么像素/字符**本身**无意义？\n",
    "\n",
    "**空间依赖性问题**：\n",
    "- 像素234是泥褐色 → 无法判断是房子还是狗\n",
    "- 字符24是\"e\" → 无法判断文本主题\n",
    "\n",
    "**特征位置可变性**：\n",
    "- 烟囱在图像左侧或右侧 → 都是\"房子\"特征\n",
    "- \"striker\"在文本不同位置 → 都表示\"足球\"\n",
    "- 相同信息由完全不同的像素/字符位置承载"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae722d76",
   "metadata": {},
   "source": [
    "## 深度神经网络"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9327e02",
   "metadata": {},
   "source": [
    "### 为什么传统模型表现不佳？\n",
    "\n",
    "**逻辑回归/随机森林/XGBoost**：\n",
    "- 依赖输入特征本身具有信息量\n",
    "- 假设特征间**相对独立**\n",
    "- *无法处理高度空间依赖的原始像素*\n",
    "- 仅适用于最简单的分类任务"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82fe1711",
   "metadata": {},
   "source": [
    "### 深度学习的核心优势\n",
    "\n",
    "**自动特征学习**：\n",
    "- **直接从原始非结构化数据学习**\n",
    "- **自动构建高层次信息特征**\n",
    "- 理解空间和时间依赖关系\n",
    "- 捕捉特征的相对位置关系\n",
    "\n",
    "**在生成式建模中的重要性**：\n",
    "- 大多数生成任务针对非结构化数据\n",
    "  - 生成新图像\n",
    "  - 创作文本\n",
    "  - 合成音频\n",
    "- 深度学习在此领域产生深远影响"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6cdcef6",
   "metadata": {},
   "source": [
    "### 神经网络组成要素\n",
    "\n",
    "**层级结构**：\n",
    "- 输入层 → 隐藏层 → 输出层\n",
    "- 每层包含多个**单元**\n",
    "\n",
    "**连接方式**：\n",
    "- **权重**：层间连接的强度参数\n",
    "- **全连接层**：每个单元连接到前一层的所有单元\n",
    "- **多层感知机**：所有相邻层都是全连接的神经网络"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35edc062",
   "metadata": {},
   "source": [
    "### 数据流动：前向传播\n",
    "\n",
    "**处理流程**：\n",
    "输入 → 层1变换 → 层2变换 → ... → 输出\n",
    "\n",
    "**单元计算**：\n",
    "1. 计算输入的加权和\n",
    "2. 应用非线性变换（激活函数）\n",
    "3. 输出传递到下一层\n",
    "\n",
    "**最终输出**：\n",
    "- 输出层产生预测概率\n",
    "- 如判断人脸是否微笑的概率"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f9075ac",
   "metadata": {},
   "source": [
    "### 如何训练神经网络？\n",
    "\n",
    "**核心目标**：\n",
    "找到使预测最准确的权重集合\n",
    "\n",
    "**训练步骤**：\n",
    "1. **前向传播**：计算预测值\n",
    "2. **误差计算**：比较预测与真实标签\n",
    "3. **反向传播**：误差从输出层向输入层传播\n",
    "4. **权重更新**：调整权重以减少误差"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ca7579f",
   "metadata": {},
   "source": [
    "### 反向传播的作用\n",
    "\n",
    "**误差反向传递**：\n",
    "- 计算每个权重对总误差的贡献\n",
    "- 沿梯度下降方向更新权重\n",
    "- 逐步优化网络预测能力"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "242a9f65",
   "metadata": {},
   "source": [
    "### 深度神经网络的核心价值\n",
    "\n",
    "1. **自动特征工程**：\n",
    "   - 无需人工设计特征\n",
    "   - 网络自动学习有用表示\n",
    "\n",
    "2. **层次化抽象**：\n",
    "   - 从简单到复杂的特征构建\n",
    "   - 逐步形成高级语义理解\n",
    "\n",
    "3. **端到端学习**：\n",
    "   - 直接从原始数据到最终预测\n",
    "   - 减少中间处理环节\n",
    "\n",
    "4. **生成式建模基础**：\n",
    "   - 理解判别模型是学习生成模型的基础\n",
    "   - 相同的神经网络原理适用于两种任务"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64e2bdcd",
   "metadata": {},
   "source": [
    "## 第一个深度神经网络"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0e95c11",
   "metadata": {},
   "source": [
    "### TensorFlow + Keras 组合\n",
    "\n",
    "**TensorFlow**：\n",
    "- 底层计算框架\n",
    "- 张量操作和梯度计算\n",
    "- 高性能数值计算\n",
    "\n",
    "**Keras**：\n",
    "- 高级API接口\n",
    "- 用户友好的模型构建\n",
    "- 快速原型开发"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3917388",
   "metadata": {},
   "source": [
    "### 三种基础层结构\n",
    "\n",
    "**Input Layer（输入层）**：\n",
    "- 网络入口点\n",
    "- 定义数据元素形状（如：`(32, 32, 3)`）\n",
    "- 不指定批次大小，支持任意数量图像\n",
    "\n",
    "**Flatten Layer（展平层）**：\n",
    "- 将多维输入展平为向量\n",
    "- 示例：`32×32×3 → 3072` 维向量\n",
    "- 为后续全连接层准备数据\n",
    "\n",
    "**Dense Layer（全连接层）**：\n",
    "- 神经网络基本构建块\n",
    "- 每个单元与前一层的所有单元连接\n",
    "- 包含权重（可正可负）和激活函数"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb0d7e79",
   "metadata": {},
   "source": [
    "### 激活函数的两种定义方式\n",
    "\n",
    "**方式一：在层内定义**\n",
    "```python\n",
    "x = layers.Dense(units=200, activation='relu')(x)\n",
    "\n",
    "**方式二：作为独立层**\n",
    "x = layers.Dense(units=200)(x)\n",
    "x = layers.Activation('relu')(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7793b96b",
   "metadata": {},
   "source": [
    "\n",
    "## 模型结构与参数分析\n",
    "\n",
    "### model.summary() 输出分析\n",
    "\n",
    "| 层类型 | 输出形状 | 参数数量 |\n",
    "|--------|----------|----------|\n",
    "| InputLayer | (None, 32, 32, 3) | 0 |\n",
    "| Flatten | (None, 3072) | 0 |\n",
    "| Dense | (None, 200) | 614,600 |\n",
    "| Dense | (None, 150) | 30,150 |\n",
    "| Dense | (None, 10) | 1,510 |\n",
    "\n",
    "**关键洞察**：\n",
    "- `None` 表示可变批次大小\n",
    "- 参数计算：`200 × (3072 + 1) = 614,600`\n",
    "- 总参数：646,260（全部可训练）"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6070215",
   "metadata": {},
   "source": [
    "### 参数数量计算详解\n",
    "\n",
    "**计算公式**：\n",
    "`本层单元数 × (前一层单元数 + 1偏置项)`\n",
    "\n",
    "**示例**：\n",
    "- 第一全连接层：`200 × (3072 + 1) = 614,600`\n",
    "- 偏置单元：确保零输入时仍有非零输出"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9658fe31",
   "metadata": {},
   "source": [
    "### 三种常用损失函数\n",
    "\n",
    "**均方误差**：\n",
    "- 适用于回归问题\n",
    "- 公式：$MSE = \\frac{1}{n} \\sum_{i=1}^{n} (y_i - p_i)^2$\n",
    "\n",
    "**分类交叉熵**：\n",
    "- 单标签多分类问题\n",
    "- 公式：$- \\sum_{i=1}^{n} y_i \\log (p_i)$\n",
    "\n",
    "**二元交叉熵**：\n",
    "- 二元分类或多标签问题\n",
    "- 公式：$- \\frac{1}{n} \\sum_{i=1}^{n} [y_i \\log(p_i) + (1-y_i)\\log(1-p_i)]$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "710c8bd0",
   "metadata": {},
   "source": [
    "### 优化器选择与调优\n",
    "\n",
    "**Adam 优化器**：\n",
    "- 最常用且稳定的选择\n",
    "- 主要调节参数：学习率\n",
    "- 示例：`learning_rate=0.0005`\n",
    "\n",
    "**学习率影响**：\n",
    "- 高学习率：训练快，但不稳定\n",
    "- 低学习率：训练慢，更稳定\n",
    "\n",
    "**编译配置**：\n",
    "```python\n",
    "model.compile(loss='categorical_crossentropy', \n",
    "              optimizer=opt, \n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6783b88a",
   "metadata": {},
   "source": [
    "\n",
    "## 模型训练过程\n",
    "\n",
    "### 1. 训练参数设置\n",
    "\n",
    "```python\n",
    "model.fit(x_train,           # ❶ 原始图像数据\n",
    "          y_train,           # ❷ one-hot编码标签\n",
    "          batch_size=32,     # ❸ 批次大小\n",
    "          epochs=10,         # ❹ 训练轮数\n",
    "          shuffle=True)      # ❺ 随机打乱数据"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52bc2e34",
   "metadata": {},
   "source": [
    "### 训练过程原理\n",
    "\n",
    "**权重初始化**：\n",
    "- 初始化为小的随机值\n",
    "\n",
    "**批次训练**：\n",
    "- 每次处理一个批次（32-256个样本）\n",
    "- 计算梯度并更新权重\n",
    "- 比全数据集训练更高效\n",
    "\n",
    "**批次大小影响**：\n",
    "- 大批次：梯度计算稳定，但速度慢\n",
    "- 小批次：训练快，但梯度噪声大\n",
    "- 现代实践：训练过程中逐渐增加批次大小"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2d3069b",
   "metadata": {},
   "source": [
    "### 训练过程原理\n",
    "\n",
    "**权重初始化**：\n",
    "- 初始化为小的随机值\n",
    "\n",
    "**批次训练**：\n",
    "- 每次处理一个批次（32-256个样本）\n",
    "- 计算梯度并更新权重\n",
    "- 比全数据集训练更高效\n",
    "\n",
    "**批次大小影响**：\n",
    "- 大批次：梯度计算稳定，但速度慢\n",
    "- 小批次：训练快，但梯度噪声大\n",
    "- 现代实践：训练过程中逐渐增加批次大小"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
